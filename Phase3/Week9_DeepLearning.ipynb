{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Week 9 \u2014 Deep Learning Basics (PyTorch)\n", "\n", "**Goals**\n", "- Understand tensors, datasets, dataloaders\n", "- Build a small MLP classifier on synthetic data\n", "- Train, evaluate, and visualize decision boundary"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 0) Setup"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Colab/local: install PyTorch if missing (CPU build is fine for demo)\n", "# In Colab, PyTorch is usually preinstalled.\n", "# !pip -q install torch matplotlib scikit-learn\n", "import torch, torch.nn as nn, torch.optim as optim\n", "from torch.utils.data import TensorDataset, DataLoader\n", "import matplotlib.pyplot as plt\n", "from sklearn.datasets import make_moons\n", "from sklearn.model_selection import train_test_split\n", "import numpy as np\n", "\n", "print('torch:', torch.__version__)\n", "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n", "device"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1) Data (make_moons synthetic)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X, y = make_moons(n_samples=1200, noise=0.2, random_state=42)\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n", "\n", "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n", "y_train_t = torch.tensor(y_train, dtype=torch.long)\n", "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n", "y_test_t = torch.tensor(y_test, dtype=torch.long)\n", "\n", "train_ds = TensorDataset(X_train_t, y_train_t)\n", "test_ds = TensorDataset(X_test_t, y_test_t)\n", "\n", "train_dl = DataLoader(train_ds, batch_size=64, shuffle=True)\n", "test_dl = DataLoader(test_ds, batch_size=256)\n", "len(train_ds), len(test_ds)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2) Model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class MLP(nn.Module):\n", "    def __init__(self):\n", "        super().__init__()\n", "        self.net = nn.Sequential(\n", "            nn.Linear(2, 32), nn.ReLU(),\n", "            nn.Linear(32, 32), nn.ReLU(),\n", "            nn.Linear(32, 2)\n", "        )\n", "    def forward(self, x): return self.net(x)\n", "\n", "model = MLP().to(device)\n", "opt = optim.Adam(model.parameters(), lr=1e-3)\n", "loss_fn = nn.CrossEntropyLoss()\n", "model"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3) Train loop"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def train_epoch(model, dl):\n", "    model.train(); total=0; correct=0; loss_sum=0.0\n", "    for xb, yb in dl:\n", "        xb, yb = xb.to(device), yb.to(device)\n", "        opt.zero_grad()\n", "        out = model(xb)\n", "        loss = loss_fn(out, yb)\n", "        loss.backward(); opt.step()\n", "        loss_sum += loss.item()*len(xb)\n", "        pred = out.argmax(1)\n", "        correct += (pred==yb).sum().item(); total += len(xb)\n", "    return loss_sum/total, correct/total\n", "\n", "def eval_epoch(model, dl):\n", "    model.eval(); total=0; correct=0; loss_sum=0.0\n", "    with torch.no_grad():\n", "        for xb, yb in dl:\n", "            xb, yb = xb.to(device), yb.to(device)\n", "            out = model(xb); loss = loss_fn(out, yb)\n", "            loss_sum += loss.item()*len(xb)\n", "            pred = out.argmax(1)\n", "            correct += (pred==yb).sum().item(); total += len(xb)\n", "    return loss_sum/total, correct/total\n", "\n", "train_hist, val_hist = [], []\n", "for epoch in range(20):\n", "    tr_loss, tr_acc = train_epoch(model, train_dl)\n", "    te_loss, te_acc = eval_epoch(model, test_dl)\n", "    train_hist.append((tr_loss,tr_acc)); val_hist.append((te_loss,te_acc))\n", "    if (epoch+1)%5==0:\n", "        print(f\"epoch {epoch+1}: train acc={tr_acc:.3f}, test acc={te_acc:.3f}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4) Visualize decision boundary"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["xx, yy = np.meshgrid(np.linspace(X[:,0].min()-0.5, X[:,0].max()+0.5, 200),\n", "                     np.linspace(X[:,1].min()-0.5, X[:,1].max()+0.5, 200))\n", "grid = np.c_[xx.ravel(), yy.ravel()]\n", "with torch.no_grad():\n", "    zz = model(torch.tensor(grid, dtype=torch.float32).to(device)).argmax(1).cpu().numpy()\n", "zz = zz.reshape(xx.shape)\n", "\n", "plt.figure()\n", "plt.contourf(xx, yy, zz, alpha=0.3, cmap='coolwarm')\n", "plt.scatter(X_test[:,0], X_test[:,1], c=y_test, cmap='coolwarm', edgecolor='k')\n", "plt.title('Decision boundary (MLP on make_moons)')\n", "plt.show()"]}], "metadata": {"colab": {"name": "Week 9 \u2014 Deep Learning (PyTorch)", "provenance": []}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": ""}}, "nbformat": 4, "nbformat_minor": 5}