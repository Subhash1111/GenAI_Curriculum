{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45552c6e",
   "metadata": {},
   "source": [
    "# Session 4 ‚Äî Data Types & File Formats\n",
    "\n",
    "Deep dive into **structured**, **semi-structured**, **unstructured**, plus **time‚Äëseries**, **graph**, and **geospatial** data. Learn common file formats, when to use them, and how they flow through pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b712ec",
   "metadata": {},
   "source": [
    "## üß≠ 1Ô∏è‚É£ Why Data Variety Matters\n",
    "\n",
    "Modern pipelines rarely handle tables alone. You‚Äôll ingest logs (JSON), documents (PDF), media (images/video), metrics (time‚Äëseries), and even relationships (graph).\n",
    "\n",
    "**Goal of this session:** understand each data type, typical storage/format choices, and how that impacts ETL, querying, and cost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361d1fad",
   "metadata": {},
   "source": [
    "## üìä 2Ô∏è‚É£ Structured Data\n",
    "\n",
    "**Definition:** Tabular data with a **fixed schema** (rows/columns).\n",
    "\n",
    "**Pros:** easy SQL querying, strong integrity (keys/constraints)\n",
    "\n",
    "**Cons:** schema changes require migration; less flexible for nested data\n",
    "\n",
    "**Examples:** CSV, TSV, Excel; relational DB tables (PostgreSQL, MySQL, SQL Server)\n",
    "\n",
    "**Mini sample (CSV):**\n",
    "```csv\n",
    "customer_id,name,region\n",
    "101,Aria,North\n",
    "102,Dev,South\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749a62b4",
   "metadata": {},
   "source": [
    "## üß© 3Ô∏è‚É£ Semi‚ÄëStructured Data\n",
    "\n",
    "**Definition:** Self‚Äëdescribing, **flexible schema** (often hierarchical/nested).\n",
    "\n",
    "**Pros:** schema evolution, good for APIs/logs; columnar formats compress well\n",
    "\n",
    "**Cons:** complex joins; requires tools that understand nested data\n",
    "\n",
    "**Examples:** JSON, XML, Parquet, Avro, YAML, logs\n",
    "\n",
    "**Mini sample (JSON):**\n",
    "```json\n",
    "{\n",
    "  \"order_id\": 9001,\n",
    "  \"customer\": { \"id\": \"C-123\", \"name\": \"Alice\" },\n",
    "  \"items\": [ { \"sku\": \"LAPTOP-15\", \"qty\": 2 } ],\n",
    "  \"total\": 2400.00\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357ab166",
   "metadata": {},
   "source": [
    "## üóÉÔ∏è 4Ô∏è‚É£ Unstructured Data\n",
    "\n",
    "**Definition:** No predefined schema; binary or free text.\n",
    "\n",
    "**Pros:** richest signals (text sentiment, images, audio)\n",
    "\n",
    "**Cons:** needs metadata/indexing; heavy processing\n",
    "\n",
    "**Examples:** PDFs, images, audio, video, emails, raw text files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdfcc5e",
   "metadata": {},
   "source": [
    "## ‚è±Ô∏è 5Ô∏è‚É£ Time‚ÄëSeries Data\n",
    "\n",
    "**Definition:** Observations indexed by **time** (regular or event‚Äëdriven). Ideal for metrics and IoT.\n",
    "\n",
    "**Stores:** TimescaleDB, InfluxDB, AWS Timestream, Azure Data Explorer\n",
    "\n",
    "**Mini sample:**\n",
    "```csv\n",
    "timestamp,temperature\n",
    "2025-10-28T10:00:00Z,22.3\n",
    "2025-10-28T10:05:00Z,22.5\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b36cc06",
   "metadata": {},
   "source": [
    "## üï∏Ô∏è 6Ô∏è‚É£ Graph Data\n",
    "\n",
    "**Definition:** Entities (**nodes**) and their **relationships** (**edges**) with properties.\n",
    "\n",
    "**Stores:** Neo4j, Amazon Neptune, Cosmos DB (Gremlin)\n",
    "\n",
    "**Mini sample (Cypher):**\n",
    "```cypher\n",
    "CREATE (a:Person {name:'Alice'})-[:FRIENDS_WITH]->(b:Person {name:'Bob'})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a22b1a",
   "metadata": {},
   "source": [
    "## üåç 7Ô∏è‚É£ Geospatial Data\n",
    "\n",
    "**Definition:** Coordinates, shapes, and spatial relationships.\n",
    "\n",
    "**Formats:** GeoJSON, Shapefile, KML\n",
    "\n",
    "**Stores/Engines:** PostGIS, BigQuery GIS, Azure Maps, AWS Location\n",
    "\n",
    "**Mini sample (GeoJSON):**\n",
    "```json\n",
    "{ \"type\": \"Point\", \"coordinates\": [77.5946, 12.9716] }\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cc187d",
   "metadata": {},
   "source": [
    "## üì¶ 8Ô∏è‚É£ Common File Formats & Compression\n",
    "\n",
    "| Format | Type | Readability | Compression | Schema | Typical Use |\n",
    "|--------|------|-------------|------------|--------|-------------|\n",
    "| CSV | Structured | Human‚Äëreadable | Poor | Static | Simple exports, interoperability |\n",
    "| JSON | Semi‚ÄëStructured | Human‚Äëreadable | Moderate | Flexible | APIs, logs, configs |\n",
    "| Parquet | Semi‚ÄëStructured (columnar) | Binary | Excellent | Embedded | Analytics over large data |\n",
    "| Avro | Semi‚ÄëStructured (row) | Binary | Excellent | External/registry | Streaming ETL, schema evolution |\n",
    "| ORC | Semi‚ÄëStructured (columnar) | Binary | Excellent | Embedded | Hadoop/Spark ecosystems |\n",
    "| XML | Semi‚ÄëStructured | Verbose | Poor | Hierarchical | Legacy systems, configs |\n",
    "| Image/Video | Unstructured | Binary | ‚Äî | ‚Äî | Media storage, ML inputs |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2607b2b",
   "metadata": {},
   "source": [
    "## üß† 9Ô∏è‚É£ Choosing the Right Format\n",
    "\n",
    "- **Human inspection?** ‚Üí CSV/JSON\n",
    "- **Analytics at scale?** ‚Üí Parquet/ORC (columnar, compress well)\n",
    "- **Streaming & schema evolution?** ‚Üí Avro (+ schema registry)\n",
    "- **Nested data?** ‚Üí JSON/Parquet\n",
    "- **Large media?** ‚Üí Object storage (S3/Blob) with metadata catalog\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8895c10",
   "metadata": {},
   "source": [
    "## üß™ üîü Practical: Read/Write Examples (CSV, JSON, Parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceae2050",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 30] Read-only file system: '/mnt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pathlib.py:1116\u001b[39m, in \u001b[36mPath.mkdir\u001b[39m\u001b[34m(self, mode, parents, exist_ok)\u001b[39m\n\u001b[32m   1115\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1116\u001b[39m     \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1117\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/mnt/data/session4_samples'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pathlib.py:1116\u001b[39m, in \u001b[36mPath.mkdir\u001b[39m\u001b[34m(self, mode, parents, exist_ok)\u001b[39m\n\u001b[32m   1115\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1116\u001b[39m     os.mkdir(\u001b[38;5;28mself\u001b[39m, mode)\n\u001b[32m   1117\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/mnt/data'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m      5\u001b[39m base = Path(\u001b[33m'\u001b[39m\u001b[33m/mnt/data/session4_samples\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mbase\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparents\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m df = pd.DataFrame([\n\u001b[32m      9\u001b[39m     {\u001b[33m'\u001b[39m\u001b[33mcustomer_id\u001b[39m\u001b[33m'\u001b[39m:\u001b[32m101\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m:\u001b[33m'\u001b[39m\u001b[33mAria\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mregion\u001b[39m\u001b[33m'\u001b[39m:\u001b[33m'\u001b[39m\u001b[33mNorth\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mamount\u001b[39m\u001b[33m'\u001b[39m:\u001b[32m250.5\u001b[39m},\n\u001b[32m     10\u001b[39m     {\u001b[33m'\u001b[39m\u001b[33mcustomer_id\u001b[39m\u001b[33m'\u001b[39m:\u001b[32m102\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m:\u001b[33m'\u001b[39m\u001b[33mDev\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mregion\u001b[39m\u001b[33m'\u001b[39m:\u001b[33m'\u001b[39m\u001b[33mSouth\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mamount\u001b[39m\u001b[33m'\u001b[39m:\u001b[32m175.0\u001b[39m},\n\u001b[32m     11\u001b[39m ])\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# CSV\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pathlib.py:1120\u001b[39m, in \u001b[36mPath.mkdir\u001b[39m\u001b[34m(self, mode, parents, exist_ok)\u001b[39m\n\u001b[32m   1118\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parents \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.parent == \u001b[38;5;28mself\u001b[39m:\n\u001b[32m   1119\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1120\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparents\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1121\u001b[39m     \u001b[38;5;28mself\u001b[39m.mkdir(mode, parents=\u001b[38;5;28;01mFalse\u001b[39;00m, exist_ok=exist_ok)\n\u001b[32m   1122\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[32m   1123\u001b[39m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[32m   1124\u001b[39m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pathlib.py:1120\u001b[39m, in \u001b[36mPath.mkdir\u001b[39m\u001b[34m(self, mode, parents, exist_ok)\u001b[39m\n\u001b[32m   1118\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parents \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.parent == \u001b[38;5;28mself\u001b[39m:\n\u001b[32m   1119\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1120\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparents\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1121\u001b[39m     \u001b[38;5;28mself\u001b[39m.mkdir(mode, parents=\u001b[38;5;28;01mFalse\u001b[39;00m, exist_ok=exist_ok)\n\u001b[32m   1122\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[32m   1123\u001b[39m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[32m   1124\u001b[39m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pathlib.py:1116\u001b[39m, in \u001b[36mPath.mkdir\u001b[39m\u001b[34m(self, mode, parents, exist_ok)\u001b[39m\n\u001b[32m   1112\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1113\u001b[39m \u001b[33;03mCreate a new directory at this given path.\u001b[39;00m\n\u001b[32m   1114\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1115\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1116\u001b[39m     os.mkdir(\u001b[38;5;28mself\u001b[39m, mode)\n\u001b[32m   1117\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[32m   1118\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parents \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.parent == \u001b[38;5;28mself\u001b[39m:\n",
      "\u001b[31mOSError\u001b[39m: [Errno 30] Read-only file system: '/mnt'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Use current directory instead of /mnt/data\n",
    "base = Path.cwd() / \"session4_samples\"\n",
    "base.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df = pd.DataFrame([\n",
    "    {'customer_id': 101, 'name': 'Aria', 'region': 'North', 'amount': 250.5},\n",
    "    {'customer_id': 102, 'name': 'Dev', 'region': 'South', 'amount': 175.0},\n",
    "])\n",
    "\n",
    "# CSV\n",
    "csv_path = base / 'customers.csv'\n",
    "df.to_csv(csv_path, index=False)\n",
    "print('Wrote:', csv_path)\n",
    "print(pd.read_csv(csv_path).head())\n",
    "\n",
    "# JSON (lines)\n",
    "json_path = base / 'customers.json'\n",
    "df.to_json(json_path, orient='records', lines=True)\n",
    "print('\\nWrote:', json_path)\n",
    "print(pd.read_json(json_path, lines=True).head())\n",
    "\n",
    "# Parquet (optional)\n",
    "parquet_path = base / 'customers.parquet'\n",
    "try:\n",
    "    df.to_parquet(parquet_path)\n",
    "    print('\\nWrote:', parquet_path)\n",
    "    print(pd.read_parquet(parquet_path).head())\n",
    "except Exception as e:\n",
    "    print('\\nParquet example skipped (install pyarrow or fastparquet):', e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac0be0a",
   "metadata": {},
   "source": [
    "### üìÑ XML Example (write/read minimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1257c2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.etree.ElementTree import Element, SubElement, tostring\n",
    "from xml.dom import minidom\n",
    "\n",
    "root = Element('customers')\n",
    "for _, row in df.iterrows():\n",
    "    c = SubElement(root, 'customer')\n",
    "    SubElement(c, 'customer_id').text = str(row['customer_id'])\n",
    "    SubElement(c, 'name').text = row['name']\n",
    "    SubElement(c, 'region').text = row['region']\n",
    "    SubElement(c, 'amount').text = str(row['amount'])\n",
    "\n",
    "xml_str = minidom.parseString(tostring(root)).toprettyxml(indent='  ')\n",
    "xml_path = base/'customers.xml'\n",
    "with open(xml_path, 'w') as f:\n",
    "    f.write(xml_str)\n",
    "print('Wrote:', xml_path)\n",
    "print('\\n'.join(xml_str.splitlines()[:10]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ee9841",
   "metadata": {},
   "source": [
    "## üñºÔ∏è 1Ô∏è‚É£1Ô∏è‚É£ Visual: Data Landscape Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d09634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import FancyBboxPatch\n",
    "\n",
    "BG   = '#f5f9ff'\n",
    "FILL = '#e0ebff'\n",
    "EDGE = '#2563eb'\n",
    "TXT  = '#111827'\n",
    "TITLE= '#0f172a'\n",
    "\n",
    "groups = [\n",
    "    ('Structured', 'CSV, Tables, Excel', 'RDBMS (Postgres, MySQL)'),\n",
    "    ('Semi-Structured', 'JSON, XML, Parquet, Avro', 'NoSQL / Docs (Mongo, Cosmos)'),\n",
    "    ('Unstructured', 'PDF, Images, Audio, Video', 'Object Stores (S3, Blob)'),\n",
    "    ('Time-Series', 'Metrics & Sensors', 'TimescaleDB, Influx, Timestream'),\n",
    "    ('Graph', 'Nodes & Edges', 'Neo4j, Neptune'),\n",
    "    ('Geospatial', 'GeoJSON, Shapefiles', 'PostGIS, BigQuery GIS')\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5.6))\n",
    "fig.patch.set_facecolor(BG); ax.set_facecolor(BG); ax.set_axis_off()\n",
    "ax.set_xlim(0, 1); ax.set_ylim(0, 1)\n",
    "\n",
    "W, H = 0.27, 0.15\n",
    "X_GAP, Y_GAP = 0.06, 0.09\n",
    "start_x = 0.07\n",
    "start_y = 0.70\n",
    "\n",
    "def box(x, y, title, ex, sys):\n",
    "    r = FancyBboxPatch((x, y), W, H, boxstyle='round,pad=0.02,rounding_size=10', fc=FILL, ec=EDGE, lw=1.5)\n",
    "    ax.add_patch(r)\n",
    "    ax.text(x+W/2, y+H*0.68, title, ha='center', va='center', fontsize=11, fontweight='bold', color=TITLE)\n",
    "    ax.text(x+W/2, y+H*0.43, ex, ha='center', va='center', fontsize=9.5, color=TXT)\n",
    "    ax.text(x+W/2, y+H*0.22, sys, ha='center', va='center', fontsize=9, color='#374151')\n",
    "\n",
    "# First row\n",
    "x = start_x\n",
    "for i in range(3):\n",
    "    t, ex, sy = groups[i]\n",
    "    box(x, start_y, t, ex, sy)\n",
    "    x += W + X_GAP\n",
    "\n",
    "# Second row\n",
    "x = start_x\n",
    "y2 = start_y - (H + Y_GAP)\n",
    "for i in range(3, 6):\n",
    "    t, ex, sy = groups[i]\n",
    "    box(x, y2, t, ex, sy)\n",
    "    x += W + X_GAP\n",
    "\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43afa974",
   "metadata": {},
   "source": [
    "## üí° 1Ô∏è‚É£2Ô∏è‚É£ Practice / Assignment\n",
    "\n",
    "1) For 12 sample files (CSV, JSON, logs, PDFs, images), **classify** the data type and format.\n",
    "\n",
    "2) Convert a JSON log file to **Parquet** and compare size and read speed (if pyarrow available).\n",
    "\n",
    "3) Build a simple **time‚Äëseries** dataframe and compute moving averages.\n",
    "\n",
    "4) Sketch a pipeline diagram showing how each data type lands in your data lake/warehouse."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
