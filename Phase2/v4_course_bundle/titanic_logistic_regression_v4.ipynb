{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# \ud83d\udcd8 Titanic Logistic Regression \u2014 v4 (CSV, EDA-first)\n\n> **v4 Enhancements**  \n> - Robust local CSV loader with fallback (`titanic.csv` or `train.csv`)  \n> - EDA-first template with clear \"What/Why\" notes  \n> - Version-agnostic metrics (manual RMSE), safe ROC plotting  \n> - Target NaN handling (drop before split)  \n> - \"What we infer\" summary cells at the end  \n> - Reproducible `random_state=42`  \n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 0) Goal & Why\n- **Task:** Predict `Survived` (0/1) \u2192 binary classification\n- **Why:** Classic example to teach metrics beyond accuracy"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1) Load Data (Local CSV)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\nimport pandas as pd, numpy as np\nfrom utils import load_titanic, basic_eda, plot_hist, bar_from_group, print_section\n\ndf = load_titanic()\ndf.head()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2) EDA \u2014 Structure, Missingness, Class Balance + Key Rates"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\nbasic_eda(df)\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\n# Class balance\nprop = df['Survived'].value_counts(normalize=True).rename('proportion')\nprop\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\n# Survival rate by Sex and Pclass\nsex_rate = df.groupby('Sex')['Survived'].mean().sort_values(ascending=False)\npclass_rate = df.groupby('Pclass')['Survived'].mean()\nbar_from_group(sex_rate, title=\"Survival Rate by Sex\", ylabel=\"Rate\", ylim01=True)\nbar_from_group(pclass_rate, title=\"Survival Rate by Pclass\", ylabel=\"Rate\", ylim01=True)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3) Target & Features (safety: drop NaN target if present)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\ncols = ['Survived','Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']\ndata = df[cols].copy()\ndata['Alone'] = ((data['SibSp'].fillna(0) + data['Parch'].fillna(0)) == 0).astype(int)\n\ndata = data.dropna(subset=['Survived']).reset_index(drop=True)\n\ny = data['Survived']\nX = data.drop(columns=['Survived'])\n\nnum_features = ['Pclass','Age','SibSp','Parch','Fare']\ncat_features = ['Sex','Embarked','Alone']\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4) Preprocessing + Split \u2014 What & Why"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n\nnumeric_transformer = Pipeline([('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())])\ncategorical_transformer = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')), ('onehot', OneHotEncoder(handle_unknown='ignore'))])\npreprocess = ColumnTransformer([('num', numeric_transformer, num_features), ('cat', categorical_transformer, cat_features)])\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5) Train & Evaluate \u2014 Metrics to report"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\nmodel = Pipeline([('preprocess', preprocess), ('clf', LogisticRegression(max_iter=1000))])\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\ny_proba = model.predict_proba(X_test)[:, 1]\n\nmetrics = {\n    'accuracy': round(accuracy_score(y_test, y_pred),3),\n    'precision': round(precision_score(y_test, y_pred),3),\n    'recall': round(recall_score(y_test, y_pred),3),\n    'f1': round(f1_score(y_test, y_pred),3),\n    'roc_auc': round(roc_auc_score(y_test, y_proba),3)\n}\nmetrics\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 6) Diagnostics \u2014 Confusion Matrix & ROC Curve"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\nfrom utils import confusion_df\nconfusion_df(y_test, y_pred)\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\nimport matplotlib.pyplot as plt\ntry:\n    from sklearn.metrics import RocCurveDisplay\n    RocCurveDisplay.from_estimator(model, X_test, y_test)\n    plt.title('ROC Curve'); plt.show()\nexcept Exception as e:\n    print(\"ROC curve not available in this sklearn version:\", e)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 7) Interpretation \u2014 Coefficients & Odds Ratios"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\nct = model.named_steps['preprocess']\nohe = ct.named_transformers_['cat'].named_steps['onehot']\nnum_names = num_features\ncat_names = list(ohe.get_feature_names_out(cat_features))\nall_feature_names = num_names + cat_names\n\ncoef = model.named_steps['clf'].coef_[0]\nimport pandas as pd, numpy as np\ncoef_df = pd.DataFrame({'feature': all_feature_names, 'coef': coef})\ncoef_df['odds_ratio'] = np.exp(coef_df['coef'])\ncoef_df.sort_values('odds_ratio', ascending=False).head(12)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## \u2705 What we infer\n- We check **accuracy + precision/recall/F1** (especially if class imbalance exists) and **ROC\u2011AUC**.\n- Confusion matrix shows failure modes.\n- Coefficients/odds help communicate drivers of survival."
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}