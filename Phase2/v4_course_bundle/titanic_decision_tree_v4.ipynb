{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# \ud83c\udf32 Titanic Decision Tree \u2014 v4 (Classification)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\n> **v4 Enhancements**  \n> - Robust local CSV loader with fallback (`titanic.csv` or `train.csv`)  \n> - EDA-first template with clear \"What/Why\" notes  \n> - Version-agnostic metrics (manual RMSE), safe ROC plotting  \n> - Target NaN handling (drop before split)  \n> - \"What we infer\" summary cells at the end  \n> - Reproducible `random_state=42`  \n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "**Why a tree?** Interpretable rules; handles nonlinearity; no scaling needed."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\nimport pandas as pd, numpy as np, matplotlib.pyplot as plt\nfrom utils import load_titanic, basic_eda\n\ndf = load_titanic()\nbasic_eda(df)\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\ncols = ['Survived','Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']\ndata = df[cols].copy()\ndata['Alone'] = ((data['SibSp'].fillna(0) + data['Parch'].fillna(0)) == 0).astype(int)\n\ny = data['Survived']\nX = data.drop(columns=['Survived'])\nnum_features = ['Pclass','Age','SibSp','Parch','Fare']\ncat_features = ['Sex','Embarked','Alone']\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\npreprocess = ColumnTransformer([\n    ('num', SimpleImputer(strategy='median'), num_features),\n    ('cat', Pipeline([('imputer', SimpleImputer(strategy='most_frequent')), ('onehot', OneHotEncoder(handle_unknown='ignore'))]), cat_features)\n])\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\nmodel = Pipeline([('preprocess', preprocess), ('clf', DecisionTreeClassifier(random_state=42, max_depth=4))])\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\n\n{'accuracy': round(accuracy_score(y_test, y_pred),3),\n 'precision': round(precision_score(y_test, y_pred),3),\n 'recall': round(recall_score(y_test, y_pred),3),\n 'f1': round(f1_score(y_test, y_pred),3)}\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "**What we infer:** Trees give simple decision rules; adjust `max_depth` to control overfitting."
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}