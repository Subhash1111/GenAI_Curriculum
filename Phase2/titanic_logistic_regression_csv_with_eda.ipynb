{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\n# \ud83d\udcd8 Notebook Outline \u2014 Titanic Logistic Regression (CSV) + EDA\n**Goal:** Predict *Survival* (0/1) using Kaggle-style Titanic CSV.\n\n## 1) Introduction \u2014 What & Why\n- **Definition:** Logistic Regression models the log-odds of the positive class as a linear function of features.\n- **Why classification:** `Survived` is binary (0/1); we need probabilities & class labels.\n- **Why Titanic:** Classic, interpretable dataset for teaching classification + metrics.\n\n## 2) Load Dataset \u2014 Local CSV\n- Use `pd.read_csv('titanic.csv')` to avoid network issues.\n\n## 3) EDA \u2014 Understand the data before modeling\n- Check class balance and missingness.\n- Visualize Age distribution and survival rates by key features.\n\n## 4) Data Preprocessing\n- **Imputation:** medians for numeric, most_frequent for categoricals.\n- **Encoding:** one\u2011hot for `Sex, Embarked`; add `Alone` feature.\n- **Scaling:** standardize numeric features.\n\n## 5) Train\u2013Test Split \u2014 Stratify on `Survived`\n\n## 6) Model Training \u2014 Logistic Regression\n\n## 7) Evaluation \u2014 Accuracy, Precision, Recall, F1, ROC\u2011AUC + diagnostics\n\n## 8) Interpretation \u2014 coefficients, odds ratios, insights\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Setup & Data Loading"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Load local CSV\ndf = pd.read_csv('titanic.csv')\nprint(df.shape)\ndf.head()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## EDA \u2014 Structure, Missingness, Class Balance"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\n# Data types and non-null counts\ndf.info()\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\n# Missing values per column\ndf.isna().sum().sort_values(ascending=False)\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\n# Class balance for Survived\ndf['Survived'].value_counts(normalize=True).rename('proportion')\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## EDA \u2014 Distributions & Survival Rates"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\n# Age distribution\nplt.figure(figsize=(6,4))\ndf['Age'].plot(kind='hist', bins=30)\nplt.xlabel('Age')\nplt.title('Age Distribution')\nplt.show()\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\n# Survival rate by Sex (bar chart via groupby)\nsex_rate = df.groupby('Sex')['Survived'].mean().sort_values(ascending=False)\nplt.figure(figsize=(6,4))\nsex_rate.plot(kind='bar')\nplt.ylabel('Survival Rate')\nplt.title('Survival Rate by Sex')\nplt.ylim(0,1)\nplt.show()\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\n# Survival rate by Pclass\npclass_rate = df.groupby('Pclass')['Survived'].mean()\nplt.figure(figsize=(6,4))\npclass_rate.plot(kind='bar')\nplt.ylabel('Survival Rate')\nplt.title('Survival Rate by Pclass')\nplt.ylim(0,1)\nplt.show()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Target & Features"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\ncols = ['Survived','Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']\ndata = df[cols].copy()\n\n# Engineered feature\ndata['Alone'] = ((data['SibSp'].fillna(0) + data['Parch'].fillna(0)) == 0).astype(int)\n\ny = data['Survived']\nX = data.drop(columns=['Survived'])\n\nnum_features = ['Pclass','Age','SibSp','Parch','Fare']\ncat_features = ['Sex','Embarked','Alone']\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Preprocessing Pipeline"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n                             roc_auc_score, confusion_matrix, RocCurveDisplay)\n\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler())\n])\n\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\npreprocess = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, num_features),\n        ('cat', categorical_transformer, cat_features)\n    ]\n)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Train\u2013Test Split"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Model \u2014 Logistic Regression"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\nmodel = Pipeline(steps=[\n    ('preprocess', preprocess),\n    ('clf', LogisticRegression(max_iter=1000))\n])\n\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\ny_proba = model.predict_proba(X_test)[:, 1]\n\nmetrics = {\n    'accuracy': round(accuracy_score(y_test, y_pred),3),\n    'precision': round(precision_score(y_test, y_pred),3),\n    'recall': round(recall_score(y_test, y_pred),3),\n    'f1': round(f1_score(y_test, y_pred),3),\n    'roc_auc': round(roc_auc_score(y_test, y_proba),3)\n}\nmetrics\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Confusion Matrix & ROC Curve"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\n# Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\npd.DataFrame(cm, index=['Actual 0','Actual 1'], columns=['Pred 0','Pred 1'])\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\n# ROC Curve\nRocCurveDisplay.from_estimator(model, X_test, y_test)\nplt.title('ROC Curve')\nplt.show()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Coefficients (Odds Interpretation)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "\n# Recover feature names\nct = model.named_steps['preprocess']\nohe = ct.named_transformers_['cat'].named_steps['onehot']\nnum_names = num_features\ncat_names = list(ohe.get_feature_names_out(cat_features))\nall_feature_names = num_names + cat_names\n\ncoef = model.named_steps['clf'].coef_[0]\ncoef_df = pd.DataFrame({'feature': all_feature_names, 'coef': coef})\ncoef_df['odds_ratio'] = np.exp(coef_df['coef'])\ncoef_df.sort_values('odds_ratio', ascending=False).head(12)\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}